{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WYVlMih95BOD",
        "outputId": "aaf12a8a-fd5b-4ed6-a0a7-3d88b26a18cc"
      },
      "outputs": [],
      "source": [
        "# MNIST Handwritten Digits Classification with CNN\n",
        "# Google Colab Ready Implementation\n",
        "\n",
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "print(\"Loading MNIST dataset...\")\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(f\"Training data shape: {x_train.shape}\")\n",
        "print(f\"Test data shape: {x_test.shape}\")\n",
        "print(f\"Number of classes: {len(np.unique(y_train))}\")\n",
        "\n",
        "# Normalize pixel values to [0, 1] range\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape data to add channel dimension (28, 28, 1) for CNN\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "num_classes = 10\n",
        "y_train_cat = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test_cat = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(f\"Preprocessed training data shape: {x_train.shape}\")\n",
        "print(f\"Preprocessed test data shape: {x_test.shape}\")\n",
        "\n",
        "# Build the CNN model\n",
        "def create_cnn_model():\n",
        "    model = keras.Sequential([\n",
        "        # First Convolutional Block\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Second Convolutional Block\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Third Convolutional Block\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "model = create_cnn_model()\n",
        "\n",
        "# Compile the model with Adam optimizer\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display model architecture\n",
        "print(\"\\nModel Architecture:\")\n",
        "model.summary()\n",
        "\n",
        "# Calculate total parameters\n",
        "total_params = model.count_params()\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "\n",
        "# Define callbacks for training\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nStarting training...\")\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train_cat,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test_cat),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\nEvaluating model...\")\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test_cat, verbose=0)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "# Check if we achieved >95% accuracy\n",
        "if test_accuracy > 0.95:\n",
        "    print(\"âœ… Successfully achieved >95% test accuracy!\")\n",
        "else:\n",
        "    print(\"âš ï¸  Test accuracy is below 95%. Consider training longer or adjusting hyperparameters.\")\n",
        "\n",
        "# Plot training history\n",
        "def plot_training_history(history):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Plot accuracy\n",
        "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax1.set_title('Model Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot loss\n",
        "    ax2.plot(history.history['loss'], label='Training Loss')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax2.set_title('Model Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)\n",
        "\n",
        "# Generate predictions for evaluation\n",
        "y_pred = model.predict(x_test, verbose=0)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=range(10), yticklabels=range(10))\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Visualize predictions on 5 sample images\n",
        "def visualize_predictions(model, x_test, y_test, num_samples=5):\n",
        "    # Select random samples\n",
        "    indices = np.random.choice(len(x_test), num_samples, replace=False)\n",
        "\n",
        "    # Get predictions\n",
        "    predictions = model.predict(x_test[indices], verbose=0)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    confidence_scores = np.max(predictions, axis=1)\n",
        "\n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
        "    if num_samples == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        # Display image\n",
        "        axes[i].imshow(x_test[idx].reshape(28, 28), cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "        # Add title with prediction info\n",
        "        true_label = y_test[idx]\n",
        "        pred_label = predicted_classes[i]\n",
        "        confidence = confidence_scores[i]\n",
        "\n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "        title = f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.3f}'\n",
        "        axes[i].set_title(title, color=color, fontsize=10)\n",
        "\n",
        "    plt.suptitle('Model Predictions on Sample Images', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return indices, predicted_classes, confidence_scores\n",
        "\n",
        "print(\"\\nVisualizing predictions on 5 sample images:\")\n",
        "sample_indices, sample_predictions, sample_confidences = visualize_predictions(model, x_test, y_test, 5)\n",
        "\n",
        "# Display detailed results for the samples\n",
        "print(\"\\nDetailed Results for Sample Images:\")\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    true_label = y_test[idx]\n",
        "    pred_label = sample_predictions[i]\n",
        "    confidence = sample_confidences[i]\n",
        "    status = \"âœ… Correct\" if true_label == pred_label else \"âŒ Incorrect\"\n",
        "    print(f\"Sample {i+1}: True={true_label}, Predicted={pred_label}, Confidence={confidence:.4f} - {status}\")\n",
        "\n",
        "# Additional analysis: Show model performance per digit\n",
        "def analyze_per_digit_performance(y_true, y_pred):\n",
        "    accuracy_per_digit = []\n",
        "    for digit in range(10):\n",
        "        digit_mask = (y_true == digit)\n",
        "        digit_accuracy = np.mean(y_pred[digit_mask] == digit)\n",
        "        accuracy_per_digit.append(digit_accuracy)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    bars = plt.bar(range(10), accuracy_per_digit, color='skyblue', edgecolor='navy')\n",
        "    plt.xlabel('Digit')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Per-Digit Classification Accuracy')\n",
        "    plt.xticks(range(10))\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add accuracy values on top of bars\n",
        "    for i, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return accuracy_per_digit\n",
        "\n",
        "print(\"\\nAnalyzing per-digit performance:\")\n",
        "digit_accuracies = analyze_per_digit_performance(y_test, y_pred_classes)\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"\\nSummary Statistics:\")\n",
        "print(f\"Overall Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Best Digit Accuracy: {max(digit_accuracies):.4f} (Digit {np.argmax(digit_accuracies)})\")\n",
        "print(f\"Worst Digit Accuracy: {min(digit_accuracies):.4f} (Digit {np.argmin(digit_accuracies)})\")\n",
        "print(f\"Average Per-Digit Accuracy: {np.mean(digit_accuracies):.4f}\")\n",
        "\n",
        "# Optional: Save the model\n",
        "print(\"\\nSaving model...\")\n",
        "model.save('mnist_cnn_model.h5')\n",
        "print(\"Model saved as 'mnist_cnn_model.h5'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MNIST CNN Classification Complete!\")\n",
        "print(f\"Final Test Accuracy: {test_accuracy*100:.2f}%\")\n",
        "if test_accuracy > 0.95:\n",
        "    print(\"ðŸŽ‰ Successfully achieved >95% accuracy target!\")\n",
        "print(\"=\"*50)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
