{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N8KGc_PJvffr",
        "outputId": "25613831-8c27-4808-bcb9-2b3d162d0777"
      },
      "outputs": [],
      "source": [
        "# Iris Species Classification using Decision Tree Classifier\n",
        "# Author: ML Practitioner\n",
        "# Dataset: Iris Species Dataset from scikit-learn\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configure matplotlib for better display\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "def load_and_explore_data():\n",
        "    \"\"\"\n",
        "    Load the Iris dataset and perform initial exploration\n",
        "    \"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"STEP 1: LOADING AND EXPLORING THE DATASET\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Load the Iris dataset\n",
        "    iris = load_iris()\n",
        "\n",
        "    # Create a DataFrame for easier manipulation\n",
        "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "    df['species'] = iris.target\n",
        "\n",
        "    # Map target numbers to actual species names\n",
        "    species_names = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
        "    df['species_name'] = df['species'].map(species_names)\n",
        "\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "    print(f\"Features: {iris.feature_names}\")\n",
        "    print(f\"Target classes: {iris.target_names}\")\n",
        "    print(\"\\nFirst 5 rows:\")\n",
        "    print(df.head())\n",
        "\n",
        "    print(\"\\nDataset info:\")\n",
        "    print(df.info())\n",
        "\n",
        "    print(\"\\nClass distribution:\")\n",
        "    print(df['species_name'].value_counts())\n",
        "\n",
        "    return df, iris\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Preprocess the data: handle missing values and encode labels\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"STEP 2: DATA PREPROCESSING\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Check for missing values\n",
        "    print(\"Missing values per column:\")\n",
        "    missing_values = df.isnull().sum()\n",
        "    print(missing_values)\n",
        "\n",
        "    if missing_values.sum() == 0:\n",
        "        print(\"✓ No missing values found in the dataset!\")\n",
        "    else:\n",
        "        print(\"⚠ Missing values detected. Handling missing values...\")\n",
        "        # For numerical features, fill with median\n",
        "        numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "        for col in numerical_cols:\n",
        "            if df[col].isnull().sum() > 0:\n",
        "                df[col].fillna(df[col].median(), inplace=True)\n",
        "                print(f\"Filled missing values in {col} with median\")\n",
        "\n",
        "    # Prepare features and target\n",
        "    feature_columns = ['sepal length (cm)', 'sepal width (cm)',\n",
        "                      'petal length (cm)', 'petal width (cm)']\n",
        "    X = df[feature_columns]\n",
        "    y = df['species']  # Already encoded as 0, 1, 2\n",
        "\n",
        "    print(f\"\\nFeatures shape: {X.shape}\")\n",
        "    print(f\"Target shape: {y.shape}\")\n",
        "    print(f\"Target classes: {np.unique(y)}\")\n",
        "\n",
        "    # Display basic statistics\n",
        "    print(\"\\nFeature statistics:\")\n",
        "    print(X.describe())\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def train_decision_tree(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Train a Decision Tree Classifier\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"STEP 3: TRAINING DECISION TREE CLASSIFIER\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Initialize the Decision Tree Classifier\n",
        "    # Using random_state for reproducibility\n",
        "    dt_classifier = DecisionTreeClassifier(\n",
        "        random_state=42,\n",
        "        max_depth=4,  # Prevent overfitting\n",
        "        min_samples_split=5,  # Minimum samples required to split\n",
        "        min_samples_leaf=2    # Minimum samples required at leaf node\n",
        "    )\n",
        "\n",
        "    print(\"Decision Tree parameters:\")\n",
        "    print(f\"- Max depth: {dt_classifier.max_depth}\")\n",
        "    print(f\"- Min samples split: {dt_classifier.min_samples_split}\")\n",
        "    print(f\"- Min samples leaf: {dt_classifier.min_samples_leaf}\")\n",
        "    print(f\"- Random state: {dt_classifier.random_state}\")\n",
        "\n",
        "    # Train the model\n",
        "    print(\"\\nTraining the model...\")\n",
        "    dt_classifier.fit(X_train, y_train)\n",
        "    print(\"✓ Model training completed!\")\n",
        "\n",
        "    # Display feature importance\n",
        "    feature_names = X_train.columns\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': dt_classifier.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\nFeature Importance:\")\n",
        "    for idx, row in importance_df.iterrows():\n",
        "        print(f\"{row['feature']}: {row['importance']:.4f}\")\n",
        "\n",
        "    return dt_classifier\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Evaluate the model using accuracy, precision, and recall\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"STEP 4: MODEL EVALUATION\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics for training set\n",
        "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "    train_precision = precision_score(y_train, y_pred_train, average='weighted')\n",
        "    train_recall = recall_score(y_train, y_pred_train, average='weighted')\n",
        "\n",
        "    # Calculate metrics for test set\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    test_precision = precision_score(y_test, y_pred_test, average='weighted')\n",
        "    test_recall = recall_score(y_test, y_pred_test, average='weighted')\n",
        "\n",
        "    print(\"TRAINING SET PERFORMANCE:\")\n",
        "    print(f\"Accuracy:  {train_accuracy:.4f}\")\n",
        "    print(f\"Precision: {train_precision:.4f}\")\n",
        "    print(f\"Recall:    {train_recall:.4f}\")\n",
        "\n",
        "    print(\"\\nTEST SET PERFORMANCE:\")\n",
        "    print(f\"Accuracy:  {test_accuracy:.4f}\")\n",
        "    print(f\"Precision: {test_precision:.4f}\")\n",
        "    print(f\"Recall:    {test_recall:.4f}\")\n",
        "\n",
        "    # Detailed classification report\n",
        "    print(\"\\nDETAILED CLASSIFICATION REPORT (Test Set):\")\n",
        "    target_names = ['setosa', 'versicolor', 'virginica']\n",
        "    print(classification_report(y_test, y_pred_test, target_names=target_names))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    print(\"CONFUSION MATRIX (Test Set):\")\n",
        "    cm = confusion_matrix(y_test, y_pred_test)\n",
        "    print(cm)\n",
        "\n",
        "    # Create a more readable confusion matrix\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                        index=['Actual ' + name for name in target_names],\n",
        "                        columns=['Predicted ' + name for name in target_names])\n",
        "    print(\"\\nConfusion Matrix (Readable Format):\")\n",
        "    print(cm_df)\n",
        "\n",
        "    return {\n",
        "        'train_accuracy': train_accuracy,\n",
        "        'test_accuracy': test_accuracy,\n",
        "        'train_precision': train_precision,\n",
        "        'test_precision': test_precision,\n",
        "        'train_recall': train_recall,\n",
        "        'test_recall': test_recall,\n",
        "        'confusion_matrix': cm,\n",
        "        'y_pred_test': y_pred_test\n",
        "    }\n",
        "\n",
        "def visualize_results(model, X, results):\n",
        "    \"\"\"\n",
        "    Create visualizations for the results\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"STEP 5: VISUALIZATIONS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Feature importance plot\n",
        "    feature_names = X.columns\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=True)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(importance_df['feature'], importance_df['importance'])\n",
        "    plt.title('Feature Importance in Decision Tree')\n",
        "    plt.xlabel('Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Confusion matrix heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    target_names = ['setosa', 'versicolor', 'virginica']\n",
        "    sns.heatmap(results['confusion_matrix'],\n",
        "                annot=True,\n",
        "                fmt='d',\n",
        "                cmap='Blues',\n",
        "                xticklabels=target_names,\n",
        "                yticklabels=target_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"✓ Visualizations created!\")\n",
        "\n",
        "def visualize_decision_tree(model, feature_names, class_names):\n",
        "    \"\"\"\n",
        "    Visualize the decision tree structure\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"STEP 6: DECISION TREE VISUALIZATION\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    try:\n",
        "        # Method 1: Graphical tree visualization\n",
        "        plt.figure(figsize=(20, 12))\n",
        "        plot_tree(model,\n",
        "                  feature_names=feature_names,\n",
        "                  class_names=class_names,\n",
        "                  filled=True,\n",
        "                  rounded=True,\n",
        "                  fontsize=10)\n",
        "        plt.title('Decision Tree Visualization', fontsize=16, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"✓ Graphical tree visualization created!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Could not create graphical visualization: {e}\")\n",
        "        print(\"This might happen in some environments. Text representation will still work.\")\n",
        "\n",
        "    # Method 2: Text-based tree representation\n",
        "    print(\"\\nTEXT REPRESENTATION OF DECISION TREE:\")\n",
        "    print(\"-\" * 50)\n",
        "    tree_rules = export_text(model,\n",
        "                            feature_names=list(feature_names),\n",
        "                            class_names=list(class_names))\n",
        "    print(tree_rules)\n",
        "\n",
        "    # Method 3: Tree structure analysis\n",
        "    print(\"\\nTREE STRUCTURE ANALYSIS:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Tree depth: {model.tree_.max_depth}\")\n",
        "    print(f\"Number of nodes: {model.tree_.node_count}\")\n",
        "    print(f\"Number of leaves: {model.tree_.n_leaves}\")\n",
        "\n",
        "    # Show decision path for a sample\n",
        "    print(\"\\nSAMPLE DECISION PATH:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"Example: For a flower with features [5.1, 3.5, 1.4, 0.2]\")\n",
        "    # Create sample with proper feature names to avoid warning\n",
        "    sample_data = [[5.1, 3.5, 1.4, 0.2]]\n",
        "    sample = pd.DataFrame(sample_data, columns=feature_names)\n",
        "    prediction = model.predict(sample)\n",
        "    prediction_proba = model.predict_proba(sample)\n",
        "\n",
        "    print(f\"Predicted class: {class_names[prediction[0]]}\")\n",
        "    print(\"Class probabilities:\")\n",
        "    for i, prob in enumerate(prediction_proba[0]):\n",
        "        print(f\"  {class_names[i]}: {prob:.4f}\")\n",
        "\n",
        "    return tree_rules\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to execute the complete pipeline\n",
        "    \"\"\"\n",
        "    print(\"IRIS SPECIES CLASSIFICATION USING DECISION TREE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        # Step 1: Load and explore data\n",
        "        df, iris_dataset = load_and_explore_data()\n",
        "\n",
        "        # Step 2: Preprocess data\n",
        "        X, y = preprocess_data(df)\n",
        "\n",
        "        # Split the data into training and testing sets\n",
        "        print(\"\\nSplitting data into train/test sets (80/20 split)...\")\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "        print(f\"Training set size: {X_train.shape[0]}\")\n",
        "        print(f\"Test set size: {X_test.shape[0]}\")\n",
        "\n",
        "        # Step 3: Train the model\n",
        "        model = train_decision_tree(X_train, y_train)\n",
        "\n",
        "        # Step 4: Evaluate the model\n",
        "        results = evaluate_model(model, X_test, y_test, X_train, y_train)\n",
        "\n",
        "        # Step 5: Create performance visualizations\n",
        "        visualize_results(model, X, results)\n",
        "\n",
        "        # Step 6: Visualize the decision tree structure\n",
        "        target_names = ['setosa', 'versicolor', 'virginica']\n",
        "        tree_rules = visualize_decision_tree(model, X.columns, target_names)\n",
        "\n",
        "        # Final summary\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"FINAL SUMMARY\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"✓ Successfully trained Decision Tree Classifier\")\n",
        "        print(f\"✓ Test Accuracy: {results['test_accuracy']:.4f}\")\n",
        "        print(f\"✓ Test Precision: {results['test_precision']:.4f}\")\n",
        "        print(f\"✓ Test Recall: {results['test_recall']:.4f}\")\n",
        "\n",
        "        if results['test_accuracy'] > 0.9:\n",
        "            print(\"🎉 Excellent performance achieved!\")\n",
        "        elif results['test_accuracy'] > 0.8:\n",
        "            print(\"👍 Good performance achieved!\")\n",
        "        else:\n",
        "            print(\"⚠ Consider tuning hyperparameters for better performance.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An error occurred: {str(e)}\")\n",
        "        print(\"Please check your environment and try again.\")\n",
        "\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
