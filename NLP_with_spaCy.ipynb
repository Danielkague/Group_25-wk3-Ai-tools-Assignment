{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2U8b5Jab_eO",
        "outputId": "792441d7-2242-4911-d465-5721db5e753e"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Load spaCy model (you'll need to install: python -m spacy download en_core_web_sm)\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except IOError:\n",
        "    print(\"Please install the English model: python -m spacy download en_core_web_sm\")\n",
        "    exit()\n",
        "\n",
        "# Sample Amazon product reviews data\n",
        "sample_reviews = [\n",
        "    \"I absolutely love my new iPhone 14! Apple has outdone themselves with this product. The camera quality is amazing and the battery life is fantastic.\",\n",
        "    \"The Samsung Galaxy S23 is okay but I expected better. The screen is nice but Samsung could improve the software experience.\",\n",
        "    \"Terrible experience with this Sony headphones. The sound quality is poor and they broke after just one week. Would not recommend Sony products.\",\n",
        "    \"Amazing Nike Air Max sneakers! Nike always delivers quality products. Very comfortable and stylish. Highly recommend!\",\n",
        "    \"The Canon EOS R5 camera is professional grade. Canon has created an excellent tool for photographers. Worth every penny!\",\n",
        "    \"Disappointed with my new MacBook Pro. Apple used to make better laptops. This one overheats and the keyboard feels cheap.\",\n",
        "    \"Love my new AirPods Pro! Apple's noise cancellation technology is incredible. Best purchase I've made this year.\",\n",
        "    \"The Dell XPS 13 laptop is decent. Dell has good build quality but the price is a bit high for what you get.\",\n",
        "    \"Awful Microsoft Surface tablet. Microsoft needs to improve their hardware quality. Screen flickering issues from day one.\",\n",
        "    \"Excellent Amazon Echo Dot! Amazon's Alexa is so helpful. Great value for money and works perfectly with my smart home setup.\"\n",
        "]\n",
        "\n",
        "class AmazonReviewAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.nlp = nlp\n",
        "\n",
        "        # Define positive and negative sentiment words\n",
        "        self.positive_words = {\n",
        "            'love', 'amazing', 'excellent', 'fantastic', 'great', 'wonderful',\n",
        "            'perfect', 'outstanding', 'brilliant', 'awesome', 'incredible',\n",
        "            'superb', 'remarkable', 'impressive', 'beautiful', 'comfortable',\n",
        "            'stylish', 'recommend', 'best', 'quality', 'helpful', 'value'\n",
        "        }\n",
        "\n",
        "        self.negative_words = {\n",
        "            'hate', 'terrible', 'awful', 'horrible', 'bad', 'poor', 'worst',\n",
        "            'disappointing', 'useless', 'broken', 'cheap', 'overpriced',\n",
        "            'disappointed', 'issues', 'problems', 'flickering', 'overheats',\n",
        "            'expensive', 'slow', 'laggy', 'defective', 'failed', 'annoying',\n",
        "            'frustrating', 'waste', 'regret', 'faulty', 'unreliable'\n",
        "        }\n",
        "\n",
        "        # Brand patterns for better extraction\n",
        "        self.brand_patterns = {\n",
        "            'Apple', 'Samsung', 'Sony', 'Nike', 'Canon', 'Dell',\n",
        "            'Microsoft', 'Amazon', 'Google', 'LG', 'HP', 'Lenovo',\n",
        "            'Adidas', 'Puma', 'Nikon', 'Panasonic', 'Bose', 'JBL'\n",
        "        }\n",
        "\n",
        "    def extract_entities(self, text):\n",
        "        \"\"\"Extract named entities from text with focus on products and brands\"\"\"\n",
        "        doc = self.nlp(text)\n",
        "\n",
        "        entities = {\n",
        "            'PERSON': [],\n",
        "            'ORG': [],  # Organizations (often brands)\n",
        "            'PRODUCT': [],  # Products\n",
        "            'BRANDS': [],  # Detected brands\n",
        "            'MONEY': [],\n",
        "            'GPE': []  # Geopolitical entities\n",
        "        }\n",
        "\n",
        "        # Extract standard spaCy entities\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ in entities:\n",
        "                entities[ent.label_].append(ent.text.strip())\n",
        "\n",
        "        # Custom brand detection (case-insensitive)\n",
        "        text_lower = text.lower()\n",
        "        for brand in self.brand_patterns:\n",
        "            if brand.lower() in text_lower:\n",
        "                # Avoid duplicates\n",
        "                if brand not in entities['BRANDS']:\n",
        "                    entities['BRANDS'].append(brand)\n",
        "\n",
        "        # Extract potential product names (capitalized phrases)\n",
        "        product_pattern = r'\\b[A-Z][a-zA-Z0-9\\s\\-]{2,30}\\b'\n",
        "        potential_products = re.findall(product_pattern, text)\n",
        "\n",
        "        # Filter and clean product names\n",
        "        for product in potential_products:\n",
        "            product = product.strip()\n",
        "            # Skip single words that are likely not products\n",
        "            if len(product.split()) == 1 and not any(char.isdigit() for char in product):\n",
        "                continue\n",
        "            # Check if it's likely a product (contains model numbers or specific terms)\n",
        "            if (any(char.isdigit() for char in product) or\n",
        "                any(term in product.lower() for term in ['pro', 'max', 'plus', 'air', 'mini', 'ultra', 'echo', 'galaxy', 'iphone', 'macbook', 'surface', 'xps'])):\n",
        "                entities['PRODUCT'].append(product)\n",
        "\n",
        "        return entities\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        \"\"\"Rule-based sentiment analysis\"\"\"\n",
        "        doc = self.nlp(text.lower())\n",
        "\n",
        "        positive_score = 0\n",
        "        negative_score = 0\n",
        "\n",
        "        # Count positive and negative words\n",
        "        for token in doc:\n",
        "            # Check for compound words and phrases\n",
        "            token_text = token.text\n",
        "            if token_text in self.positive_words:\n",
        "                positive_score += 1\n",
        "            elif token_text in self.negative_words:\n",
        "                negative_score += 1\n",
        "\n",
        "        # Check for multi-word phrases like \"not recommend\"\n",
        "        text_lower = text.lower()\n",
        "        if \"not recommend\" in text_lower or \"don't recommend\" in text_lower or \"wouldn't recommend\" in text_lower:\n",
        "            negative_score += 2\n",
        "        if \"highly recommend\" in text_lower or \"definitely recommend\" in text_lower:\n",
        "            positive_score += 2\n",
        "\n",
        "        # Check for negations that might flip sentiment\n",
        "        negation_words = {'not', 'no', 'never', 'nothing', 'nowhere', 'nobody', 'none', 'neither', \"n't\", 'dont', \"don't\"}\n",
        "        tokens_list = [token.text for token in doc]\n",
        "\n",
        "        # Simple negation handling - look ahead 2-3 words after negation\n",
        "        for i, token in enumerate(tokens_list):\n",
        "            if token in negation_words:\n",
        "                # Check next 1-3 tokens after negation\n",
        "                for j in range(1, min(4, len(tokens_list) - i)):\n",
        "                    if i + j < len(tokens_list):\n",
        "                        next_token = tokens_list[i + j]\n",
        "                        if next_token in self.positive_words:\n",
        "                            positive_score = max(0, positive_score - 1)\n",
        "                            negative_score += 1\n",
        "                            break  # Only flip the first positive word found\n",
        "\n",
        "        # Determine overall sentiment\n",
        "        total_words = positive_score + negative_score\n",
        "        if total_words == 0:\n",
        "            sentiment = \"NEUTRAL\"\n",
        "            confidence = 0.5\n",
        "        elif positive_score > negative_score:\n",
        "            sentiment = \"POSITIVE\"\n",
        "            confidence = positive_score / total_words\n",
        "        elif negative_score > positive_score:\n",
        "            sentiment = \"NEGATIVE\"\n",
        "            confidence = negative_score / total_words\n",
        "        else:\n",
        "            sentiment = \"NEUTRAL\"\n",
        "            confidence = 0.5\n",
        "\n",
        "        return {\n",
        "            'sentiment': sentiment,\n",
        "            'confidence': round(confidence, 2),\n",
        "            'positive_score': positive_score,\n",
        "            'negative_score': negative_score\n",
        "        }\n",
        "\n",
        "    def analyze_review(self, review_text):\n",
        "        \"\"\"Complete analysis of a single review\"\"\"\n",
        "        entities = self.extract_entities(review_text)\n",
        "        sentiment = self.analyze_sentiment(review_text)\n",
        "\n",
        "        return {\n",
        "            'review': review_text,\n",
        "            'entities': entities,\n",
        "            'sentiment': sentiment\n",
        "        }\n",
        "\n",
        "    def analyze_multiple_reviews(self, reviews):\n",
        "        \"\"\"Analyze multiple reviews and provide summary\"\"\"\n",
        "        results = []\n",
        "        all_brands = []\n",
        "        all_products = []\n",
        "        sentiment_counts = Counter()\n",
        "\n",
        "        print(\"=== AMAZON REVIEWS NLP ANALYSIS ===\\n\")\n",
        "\n",
        "        for i, review in enumerate(reviews, 1):\n",
        "            result = self.analyze_review(review)\n",
        "            results.append(result)\n",
        "\n",
        "            print(f\"REVIEW {i}:\")\n",
        "            print(f\"Text: {review[:100]}...\")\n",
        "            print(f\"Sentiment: {result['sentiment']['sentiment']} (Confidence: {result['sentiment']['confidence']})\")\n",
        "\n",
        "            # Display entities\n",
        "            entities = result['entities']\n",
        "            if entities['BRANDS']:\n",
        "                print(f\"Brands: {', '.join(set(entities['BRANDS']))}\")\n",
        "                all_brands.extend(entities['BRANDS'])\n",
        "\n",
        "            if entities['PRODUCT']:\n",
        "                print(f\"Products: {', '.join(set(entities['PRODUCT']))}\")\n",
        "                all_products.extend(entities['PRODUCT'])\n",
        "\n",
        "            if entities['ORG']:\n",
        "                print(f\"Organizations: {', '.join(set(entities['ORG']))}\")\n",
        "\n",
        "            sentiment_counts[result['sentiment']['sentiment']] += 1\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        # Summary statistics\n",
        "        print(\"\\n=== ANALYSIS SUMMARY ===\")\n",
        "        print(f\"Total Reviews Analyzed: {len(reviews)}\")\n",
        "\n",
        "        print(f\"\\nSentiment Distribution:\")\n",
        "        for sentiment, count in sentiment_counts.items():\n",
        "            percentage = (count / len(reviews)) * 100\n",
        "            print(f\"  {sentiment}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "        if all_brands:\n",
        "            brand_counts = Counter(all_brands)\n",
        "            print(f\"\\nMost Mentioned Brands:\")\n",
        "            for brand, count in brand_counts.most_common(5):\n",
        "                print(f\"  {brand}: {count} mentions\")\n",
        "\n",
        "        if all_products:\n",
        "            product_counts = Counter(all_products)\n",
        "            print(f\"\\nMost Mentioned Products:\")\n",
        "            for product, count in product_counts.most_common(5):\n",
        "                print(f\"  {product}: {count} mentions\")\n",
        "\n",
        "        return results\n",
        "\n",
        "# Initialize analyzer and run analysis\n",
        "if __name__ == \"__main__\":\n",
        "    analyzer = AmazonReviewAnalyzer()\n",
        "\n",
        "    # Analyze sample reviews\n",
        "    results = analyzer.analyze_multiple_reviews(sample_reviews)\n",
        "\n",
        "    # Example of analyzing a single review\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SINGLE REVIEW DETAILED ANALYSIS:\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    single_review = \"The new Apple iPhone 14 Pro Max is absolutely incredible! Apple has created the best smartphone ever. The camera quality is outstanding and the A16 chip makes everything lightning fast. Highly recommend this product to everyone!\"\n",
        "\n",
        "    single_result = analyzer.analyze_review(single_review)\n",
        "\n",
        "    print(f\"Review: {single_result['review']}\")\n",
        "    print(f\"\\nSentiment Analysis:\")\n",
        "    print(f\"  Sentiment: {single_result['sentiment']['sentiment']}\")\n",
        "    print(f\"  Confidence: {single_result['sentiment']['confidence']}\")\n",
        "    print(f\"  Positive Words Found: {single_result['sentiment']['positive_score']}\")\n",
        "    print(f\"  Negative Words Found: {single_result['sentiment']['negative_score']}\")\n",
        "\n",
        "    print(f\"\\nNamed Entity Recognition:\")\n",
        "    for entity_type, entities in single_result['entities'].items():\n",
        "        if entities:\n",
        "            print(f\"  {entity_type}: {', '.join(set(entities))}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
